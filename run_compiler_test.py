# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: run_compiler_test.py
# (æ›´æ–°)
#
# Title: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚³ãƒ³ãƒ‘ã‚¤ãƒ© ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# Description:
# - ãƒ­ãƒ¼ãƒ‰ãƒžãƒƒãƒ—ã€Œãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¸ã®æœ€é©åŒ–ã€ã§å®Ÿè£…ã—ãŸ
#   NeuromorphicCompilerã®å‹•ä½œã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
# - ãƒ€ãƒŸãƒ¼ã®BioSNNãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ãã‚Œã‚’ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã«
#   ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
#
# æ”¹å–„ç‚¹(v2):
# - ROADMAPãƒ•ã‚§ãƒ¼ã‚º6ã«åŸºã¥ãã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¾Œã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ€§èƒ½ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹å‡¦ç†ã‚’è¿½åŠ ã€‚
# æ”¹å–„ç‚¹(v3): ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«å­¦ç¿’å‰‡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹æ¤œè¨¼ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ã€‚
# æ”¹å–„ç‚¹(snn_4_ann_parity_plan):
# - å­¦ç¿’å‰‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ã‚’ã‚ˆã‚ŠåŽ³å¯†åŒ–ã€‚
# - å¤ã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å‰Šé™¤ã—ã€ã“ã¡ã‚‰ã«æ©Ÿèƒ½ã‚’çµ±åˆã€‚
# - ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨ã—ã€æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚

import sys
from pathlib import Path
import os
import torch
import yaml
import copy

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).resolve().parent))

from snn_research.bio_models.simple_network import BioSNN
from snn_research.learning_rules.causal_trace import CausalTraceCreditAssignment
from snn_research.hardware.compiler import NeuromorphicCompiler
from snn_research.training.pruning import apply_magnitude_pruning

def main():
    """
    NeuromorphicCompilerã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚‚æ¤œè¨¼ã™ã‚‹ã€‚
    """
    print("--- ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚³ãƒ³ãƒ‘ã‚¤ãƒ© ãƒ†ã‚¹ãƒˆé–‹å§‹ ---")

    # 1. ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¯¾è±¡ã®ãƒ€ãƒŸãƒ¼BioSNNãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
    learning_rate = 0.005
    learning_rule = CausalTraceCreditAssignment(
        learning_rate=learning_rate, a_plus=1.0, a_minus=1.0,
        tau_trace=20.0, tau_eligibility=50.0
    )
    model = BioSNN(
        layer_sizes=[10, 20, 5], # 3å±¤ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        neuron_params={'tau_mem': 10.0, 'v_threshold': 1.0, 'v_reset': 0.0, 'v_rest': 0.0},
        learning_rule=learning_rule
    )
    print("âœ… ãƒ€ãƒŸãƒ¼ã®BioSNNãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚")
    
    # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å‰ã®ç·æŽ¥ç¶šæ•°ã‚’è¨ˆç®— (éžã‚¼ãƒ­ã®é‡ã¿)
    original_connections = sum(torch.sum(w > 0).item() for w in model.weights)

    # 2. ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é©ç”¨
    pruning_amount = 0.3 # 30%ã®é‡ã¿ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
    pruned_model = apply_magnitude_pruning(copy.deepcopy(model), amount=pruning_amount)
    pruned_connections = sum(torch.sum(w > 0).item() for w in pruned_model.weights)
    print(f"ðŸ”ª ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ãŸ: {original_connections} -> {pruned_connections} connections")
    assert pruned_connections < original_connections, "ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦æŽ¥ç¶šæ•°ãŒæ¸›å°‘ã—ã¾ã›ã‚“ã§ã—ãŸã€‚"

    # 3. ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã®åˆæœŸåŒ–
    compiler = NeuromorphicCompiler(hardware_profile_name="default")

    # 4. ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
    output_dir = "runs/compiler_tests"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "compiled_pruned_hardware_config.yaml")
    
    compiler.compile(pruned_model, output_path)

    # 5. çµæžœã®ç¢ºèª
    if os.path.exists(output_path):
        print(f"\nâœ… ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸ: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒ '{output_path}' ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚")
        
        # 5.1. ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«çµæžœã‚’æ¤œè¨¼
        with open(output_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # 5.1.1. å­¦ç¿’å‰‡ã®æ¤œè¨¼
        assert "learning_rule_config" in config, "å­¦ç¿’å‰‡ã®è¨­å®šãŒYAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ã‚Šã¾ã›ã‚“ã€‚"
        lr_config = config["learning_rule_config"]
        assert lr_config["rule_name"] == "CausalTraceCreditAssignment", "å­¦ç¿’å‰‡ã®åå‰ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚"
        assert "parameters" in lr_config, "å­¦ç¿’å‰‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒYAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ã‚Šã¾ã›ã‚“ã€‚"
        params = lr_config["parameters"]
        assert "learning_rate" in params and abs(params["learning_rate"] - learning_rate) < 1e-6, "å­¦ç¿’çŽ‡ãŒæ­£ã—ãã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        print("  - æ¤œè¨¼: å­¦ç¿’å‰‡ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«çµæžœã¯æ­£å¸¸ã§ã™ã€‚")
        
        # 5.1.2. ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°çµæžœã®æ¤œè¨¼
        compiled_connections = sum(layer['num_connections'] for layer in config['synaptic_connectivity'])
        assert compiled_connections == pruned_connections, "ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸæŽ¥ç¶šæ•°ãŒãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«ã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚"
        print(f"  - æ¤œè¨¼: ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°çµæžœãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«æ­£ã—ãåæ˜ ã•ã‚Œã¾ã—ãŸ ({compiled_connections} connections)ã€‚")

        # 6. ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ä¸Šã§ã®æ€§èƒ½ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
        total_spikes_for_simulation = 15000
        time_steps_for_simulation = 100
        
        simulation_report = compiler.simulate_on_hardware(
            compiled_config_path=output_path,
            total_spikes=total_spikes_for_simulation,
            time_steps=time_steps_for_simulation
        )
        
        print("\n--- ðŸ“Š ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæžœ ---")
        for key, value in simulation_report.items():
            print(f"  - {key}: {value:.4e}")
        print("------------------------------------------")
        
    else:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    print("\n--- ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ¢ãƒ¼ãƒ•ã‚£ãƒƒã‚¯ãƒ»ã‚³ãƒ³ãƒ‘ã‚¤ãƒ© ãƒ†ã‚¹ãƒˆçµ‚äº† ---")


if __name__ == "__main__":
    main()
