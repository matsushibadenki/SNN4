# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/training/trainers.py
# (æ›´æ–°)
# ä¿®æ­£ç‚¹: mypyã‚¨ãƒ©ãƒ¼ [call-arg] ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€DistillationTrainerå†…ã®
#         æœªä½¿ç”¨ã‹ã¤å‹æ¨è«–ã‚’æ··ä¹±ã•ã›ã¦ã„ãŸ train ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‰Šé™¤ã€‚
# ä¿®æ­£ç‚¹(v2): PyTorchã®UserWarningã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€train_epochãƒ¡ã‚½ãƒƒãƒ‰å†…ã®
#            scheduler.step()ã®å‘¼ã³å‡ºã—æ–¹ã‚’ä¿®æ­£ã€‚
# æ”¹å–„ç‚¹(v3): ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨çŠ¶æ…‹ã‚’å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®
#            è¨˜éŒ²ãƒ»æç”»æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from omegaconf import DictConfig
import os
import collections
from tqdm import tqdm
from typing import Tuple, Dict, Any, Optional, cast
import shutil
import time
from torch.optim import Adam
from spikingjelly.activation_based import functional # type: ignore
from pathlib import Path

from snn_research.training.losses import CombinedLoss, DistillationLoss, SelfSupervisedLoss, PhysicsInformedLoss, PlannerLoss, ProbabilisticEnsembleLoss
from snn_research.cognitive_architecture.astrocyte_network import AstrocyteNetwork
from snn_research.cognitive_architecture.meta_cognitive_snn import MetaCognitiveSNN
from torch.utils.tensorboard import SummaryWriter
from snn_research.visualization.neuron_dynamics import NeuronDynamicsRecorder, plot_neuron_dynamics
from snn_research.core.neurons import AdaptiveLIFNeuron

from snn_research.bio_models.simple_network import BioSNN
import copy


class BreakthroughTrainer:
    def __init__(self, model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.Module,
                 scheduler: Optional[torch.optim.lr_scheduler.LRScheduler], device: str,
                 grad_clip_norm: float, rank: int, use_amp: bool, log_dir: str,
                 astrocyte_network: Optional[AstrocyteNetwork] = None,
                 meta_cognitive_snn: Optional[MetaCognitiveSNN] = None,
                 enable_visualization: bool = True): # å¯è¦–åŒ–ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
        self.model = model
        self.device = device
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.criterion = criterion
        self.grad_clip_norm = grad_clip_norm
        self.rank = rank
        self.use_amp = use_amp and self.device != 'mps'
        self.astrocyte_network = astrocyte_network
        self.meta_cognitive_snn = meta_cognitive_snn
        
        self.scaler = torch.amp.GradScaler(enabled=self.use_amp)
        self.best_metric = float('inf')
        
        if self.rank in [-1, 0]:
            self.writer = SummaryWriter(log_dir)
            print(f"âœ… TensorBoard logging enabled. Log directory: {log_dir}")

        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“è¿½åŠ é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        self.enable_visualization = enable_visualization
        if self.enable_visualization:
            self.recorder = NeuronDynamicsRecorder(max_timesteps=100)
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘è¿½åŠ çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸


    def _run_step(self, batch: Tuple[torch.Tensor, ...], is_train: bool) -> Dict[str, Any]:
        functional.reset_net(self.model)
        start_time = time.time()
        if is_train:
            self.model.train()
        else:
            self.model.eval()
            # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“è¿½åŠ é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
            if self.enable_visualization:
                self.recorder.clear()
            # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘è¿½åŠ çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸

        input_ids, target_ids = [t.to(self.device) for t in batch[:2]]
        
        with torch.amp.autocast(device_type=self.device if self.device != 'mps' else 'cpu', enabled=self.use_amp):
            with torch.set_grad_enabled(is_train):
                # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
                # å¯è¦–åŒ–ã®ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å°‘ã—å¤‰æ›´
                if not is_train and self.enable_visualization:
                    # è©•ä¾¡æ™‚ã¯ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«çŠ¶æ…‹ã‚’è¨˜éŒ²
                    logits, spikes, mem = self._forward_with_recording(input_ids)
                else:
                    logits, spikes, mem = self.model(input_ids, return_spikes=True, return_full_mems=True)
                # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
                
                loss_dict = self.criterion(logits, target_ids, spikes, mem, self.model)
        
        if is_train:
            self.optimizer.zero_grad()
            if self.use_amp:
                self.scaler.scale(loss_dict['total']).backward()
                if self.grad_clip_norm > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss_dict['total'].backward()
                if self.grad_clip_norm > 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                self.optimizer.step()
            
            if self.meta_cognitive_snn:
                end_time = time.time()
                computation_time = end_time - start_time
                with torch.no_grad():
                    preds = torch.argmax(logits, dim=-1)
                    if hasattr(self.criterion, 'ce_loss_fn') and hasattr(self.criterion.ce_loss_fn, 'ignore_index'):
                        ignore_idx = self.criterion.ce_loss_fn.ignore_index
                        mask = target_ids != ignore_idx
                        num_masked_elements = cast(torch.Tensor, mask).sum()
                        accuracy = (preds[mask] == target_ids[mask]).float().sum() / num_masked_elements if num_masked_elements > 0 else torch.tensor(0.0)
                        loss_dict['accuracy'] = accuracy.item()
                
                self.meta_cognitive_snn.update_metadata(
                    loss=loss_dict['total'].item(),
                    computation_time=computation_time,
                    accuracy=loss_dict.get('accuracy', 0.0)
                )

        with torch.no_grad():
            if 'accuracy' not in loss_dict:
                preds = torch.argmax(logits, dim=-1)
                if hasattr(self.criterion, 'ce_loss_fn') and hasattr(self.criterion.ce_loss_fn, 'ignore_index'):
                    ignore_idx = self.criterion.ce_loss_fn.ignore_index
                    mask = target_ids != ignore_idx
                    num_masked_elements = cast(torch.Tensor, mask).sum()
                    accuracy = (preds[mask] == target_ids[mask]).float().sum() / num_masked_elements if num_masked_elements > 0 else torch.tensor(0.0)
                    loss_dict['accuracy'] = accuracy

        return {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()}
        
    # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“è¿½åŠ é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
    def _forward_with_recording(self, input_ids: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """çŠ¶æ…‹ã‚’è¨˜éŒ²ã—ãªãŒã‚‰ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
        # ã“ã®å®Ÿè£…ã¯BreakthroughSNNã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’æ¨¡å€£ã—ã¦ã„ã¾ã™ã€‚
        # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚
        model_to_run = self.model.module if isinstance(self.model, nn.parallel.DistributedDataParallel) else self.model

        # å†…éƒ¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ã‚’å–å¾—
        neuron_layers = [m for m in model_to_run.modules() if isinstance(m, AdaptiveLIFNeuron)]
        if not neuron_layers:
            # è¨˜éŒ²å¯¾è±¡ãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å®Ÿè¡Œ
            return self.model(input_ids, return_spikes=True, return_full_mems=True)
            
        # è¨˜éŒ²å¯¾è±¡ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆä¾‹ï¼šæœ€åˆã®LIFå±¤ï¼‰
        target_neuron = neuron_layers[0]

        # ç°¡æ˜“çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å®Ÿè¡Œã¨è¨˜éŒ²
        B, L = input_ids.shape
        x_emb = model_to_run.model.token_embedding(input_ids)
        
        all_logits = []
        all_spikes = []
        all_mems = []

        for t in range(model_to_run.model.time_steps):
            # 1ã‚¹ãƒ†ãƒƒãƒ—åˆ†ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å‡¦ç†ï¼ˆãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨å®Ÿè£…ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ç°¡æ˜“åŒ–ï¼‰
            logits, spikes, mem = model_to_run(input_ids, return_spikes=True, return_full_mems=True)
            
            # æœ€åˆã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æœ€åˆã®ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒ«ã®çŠ¶æ…‹ã‚’è¨˜éŒ²
            self.recorder.record(
                membrane=target_neuron.mem.unsqueeze(0),
                threshold=target_neuron.adaptive_threshold.unsqueeze(0),
                spikes=spikes.unsqueeze(0)
            )
            all_logits.append(logits)
            all_spikes.append(spikes)
            all_mems.append(mem)

        final_logits = torch.stack(all_logits).mean(0)
        avg_spikes = torch.stack(all_spikes).mean()
        avg_mem = torch.stack(all_mems).mean()

        return final_logits, avg_spikes, avg_mem
    # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘è¿½åŠ çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸

    def train_epoch(self, dataloader: DataLoader, epoch: int) -> Dict[str, float]:
        total_metrics: Dict[str, float] = collections.defaultdict(float)
        num_batches = len(dataloader)
        progress_bar = tqdm(dataloader, desc=f"Training Epoch {epoch}", disable=(self.rank not in [-1, 0]))
        
        self.model.train()
        for batch in progress_bar:
            metrics = self._run_step(batch, is_train=True)
            for key, value in metrics.items(): total_metrics[key] += value
            progress_bar.set_postfix({k: v / (progress_bar.n + 1) for k, v in total_metrics.items()})

        if self.scheduler:
            self.scheduler.step()
        
        avg_metrics = {key: value / num_batches for key, value in total_metrics.items()}
        
        if self.rank in [-1, 0]:
            for key, value in avg_metrics.items():
                self.writer.add_scalar(f'Train/{key}', value, epoch)
            if self.scheduler:
                self.writer.add_scalar('Train/learning_rate', self.scheduler.get_last_lr()[0], epoch)
            else:
                self.writer.add_scalar('Train/learning_rate', self.optimizer.param_groups[0]['lr'], epoch)
        
        return avg_metrics


    def evaluate(self, dataloader: DataLoader, epoch: int) -> Dict[str, float]:
        total_metrics: Dict[str, float] = collections.defaultdict(float)
        num_batches = len(dataloader)
        progress_bar = tqdm(dataloader, desc=f"Evaluating Epoch {epoch}", disable=(self.rank not in [-1, 0]))
        
        self.model.eval()
        with torch.no_grad():
            for i, batch in enumerate(progress_bar):
                # æœ€åˆã®ãƒãƒƒãƒã®ã¿å¯è¦–åŒ–ã‚’å®Ÿè¡Œ
                is_first_batch = i == 0
                metrics = self._run_step(batch, is_train=False)
                for key, value in metrics.items(): total_metrics[key] += value
        
        avg_metrics = {key: value / num_batches for key, value in total_metrics.items()}
        
        if self.rank in [-1, 0]:
            print(f"Epoch {epoch} Validation Results: " + ", ".join([f"{k}: {v:.4f}" for k, v in avg_metrics.items()]))
            for key, value in avg_metrics.items():
                self.writer.add_scalar(f'Validation/{key}', value, epoch)
            
            # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“è¿½åŠ é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
            if self.enable_visualization and self.recorder.history['membrane']:
                try:
                    save_path = Path(self.writer.log_dir) / f"neuron_dynamics_epoch_{epoch}.png"
                    plot_neuron_dynamics(self.recorder.history, save_path=save_path)
                    print(f"ğŸ“Š Neuron dynamics visualization saved to {save_path}")
                except Exception as e:
                    print(f"âš ï¸ Failed to generate neuron dynamics plot: {e}")
            # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘è¿½åŠ çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸

        return avg_metrics


    def save_checkpoint(self, path: str, epoch: int, metric_value: float, **kwargs: Any):
        if self.rank in [-1, 0]:
            model_to_save_container = self.model.module if isinstance(self.model, nn.parallel.DistributedDataParallel) else self.model
            actual_model = cast(nn.Module, model_to_save_container.model if hasattr(model_to_save_container, 'model') else model_to_save_container)
            
            buffers_to_exclude = {
                name for name, buf in actual_model.named_buffers() 
                if any(keyword in name for keyword in ['mem', 'spikes', 'adaptive_threshold'])
            }
            model_state = {k: v for k, v in actual_model.state_dict().items() if k not in buffers_to_exclude}

            state = {
                'epoch': epoch, 'model_state_dict': model_state, 
                'optimizer_state_dict': self.optimizer.state_dict(),
                'best_metric': self.best_metric
            }
            if self.use_amp: state['scaler_state_dict'] = self.scaler.state_dict()
            if self.scheduler: state['scheduler_state_dict'] = self.scheduler.state_dict()
            state.update(kwargs)
            
            os.makedirs(os.path.dirname(path), exist_ok=True)
            torch.save(state, path)
            print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ '{path}' ã«ä¿å­˜ã—ã¾ã—ãŸ (Epoch: {epoch})ã€‚")
            
            if metric_value < self.best_metric:
                self.best_metric = metric_value
                best_path = os.path.join(os.path.dirname(path), 'best_model.pth')
                temp_state_for_best = {'model_state_dict': model_state, **kwargs}
                torch.save(temp_state_for_best, best_path)
                print(f"ğŸ† æ–°ã—ã„ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ '{best_path}' ã«ä¿å­˜ã—ã¾ã—ãŸ (Metric: {metric_value:.4f})ã€‚")

    def load_checkpoint(self, path: str) -> int:
        if not os.path.exists(path):
            print(f"âš ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}ã€‚æœ€åˆã‹ã‚‰å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            return 0
            
        checkpoint = torch.load(path, map_location=self.device)
        model_to_load_container = self.model.module if isinstance(self.model, nn.parallel.DistributedDataParallel) else self.model
        actual_model = cast(nn.Module, model_to_load_container.model if hasattr(model_to_load_container, 'model') else model_to_load_container)
        actual_model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        
        if 'optimizer_state_dict' in checkpoint: self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if self.scheduler and 'scheduler_state_dict' in checkpoint: self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        if self.use_amp and 'scaler_state_dict' in checkpoint: self.scaler.load_state_dict(checkpoint['scaler_state_dict'])

        self.best_metric = checkpoint.get('best_metric', float('inf'))
        start_epoch = checkpoint.get('epoch', 0) + 1
        print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ '{path}' ã‚’æ­£å¸¸ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚Epoch {start_epoch} ã‹ã‚‰å­¦ç¿’ã‚’å†é–‹ã—ã¾ã™ã€‚")
        return start_epoch

class DistillationTrainer(BreakthroughTrainer):
    # mypyã‚¨ãƒ©ãƒ¼[call-arg]ã®åŸå› ã¨ãªã£ã¦ã„ãŸæœªä½¿ç”¨ã®trainãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‰Šé™¤ã€‚
    # è¦ªã‚¯ãƒ©ã‚¹ã®train_epochãŒç›´æ¥ä½¿ç”¨ã•ã‚Œã‚‹ã€‚

    def _run_step(self, batch: Tuple[torch.Tensor, ...], is_train: bool) -> Dict[str, Any]:
        functional.reset_net(self.model)
        if is_train: self.model.train()
        else: self.model.eval()
            
        student_input, attention_mask, student_target, teacher_logits = [t.to(self.device) for t in batch]

        with torch.amp.autocast(device_type=self.device if self.device != 'mps' else 'cpu', enabled=self.use_amp):
            with torch.set_grad_enabled(is_train):
                student_logits, spikes, mem = self.model(student_input, return_spikes=True, return_full_mems=True)
                
                assert isinstance(self.criterion, DistillationLoss)
                loss_dict = self.criterion(
                    student_logits=student_logits, teacher_logits=teacher_logits, targets=student_target,
                    spikes=spikes, mem=mem, model=self.model, attention_mask=attention_mask
                )
        
        if is_train:
            self.optimizer.zero_grad()
            self.scaler.scale(loss_dict['total']).backward()
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
            self.scaler.step(self.optimizer)
            self.scaler.update()
            
            # if self.astrocyte_network: self.astrocyte_network.step()
        
        with torch.no_grad():
            preds = torch.argmax(student_logits, dim=-1)
            ignore_idx = self.criterion.ce_loss_fn.ignore_index
            mask = student_target != ignore_idx
            
            num_valid_tokens = mask.sum()
            if num_valid_tokens > 0:
                accuracy = (preds[mask] == student_target[mask]).float().sum() / num_valid_tokens
            else:
                accuracy = torch.tensor(0.0, device=self.device)
            loss_dict['accuracy'] = accuracy
        
        return {k: v.cpu().item() if torch.is_tensor(v) else v for k, v in loss_dict.items()}

class SelfSupervisedTrainer(BreakthroughTrainer):
    pass

class PhysicsInformedTrainer(BreakthroughTrainer):
    def _run_step(self, batch: Tuple[torch.Tensor, ...], is_train: bool) -> Dict[str, Any]:
        functional.reset_net(self.model)
        if is_train:
            self.model.train()
        else:
            self.model.eval()

        input_ids, target_ids = [t.to(self.device) for t in batch[:2]]
        
        with torch.amp.autocast(device_type=self.device if self.device != 'mps' else 'cpu', enabled=self.use_amp):
            with torch.set_grad_enabled(is_train):
                logits, spikes, mem_sequence = self.model(input_ids, return_spikes=True, return_full_mems=True)
                loss_dict = self.criterion(logits, target_ids, spikes, mem_sequence, self.model)
        
        if is_train:
            self.optimizer.zero_grad()
            if self.use_amp:
                self.scaler.scale(loss_dict['total']).backward()
                if self.grad_clip_norm > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss_dict['total'].backward()
                if self.grad_clip_norm > 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                self.optimizer.step()
            
            # if self.astrocyte_network:
            #     self.astrocyte_network.step()

        with torch.no_grad():
            preds = torch.argmax(logits, dim=-1)
            if hasattr(self.criterion, "ce_loss_fn") and hasattr(self.criterion.ce_loss_fn, 'ignore_index'):
                ignore_idx = self.criterion.ce_loss_fn.ignore_index
                mask = target_ids != ignore_idx
                num_masked_elements = cast(torch.Tensor, mask).sum()
                accuracy = (preds[mask] == target_ids[mask]).float().sum() / num_masked_elements if num_masked_elements > 0 else torch.tensor(0.0)
                loss_dict['accuracy'] = accuracy

        return {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()}

class ProbabilisticEnsembleTrainer(BreakthroughTrainer):
    def __init__(self, ensemble_size: int = 5, **kwargs):
        super().__init__(**kwargs)
        self.ensemble_size = ensemble_size

    def _run_step(self, batch: Tuple[torch.Tensor, ...], is_train: bool) -> Dict[str, Any]:
        if is_train:
            self.model.train()
        else:
            self.model.eval()

        input_ids, target_ids = [t.to(self.device) for t in batch[:2]]
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®ãŸã‚ã«è¤‡æ•°å›ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚’å®Ÿè¡Œ
        ensemble_logits = []
        for _ in range(self.ensemble_size):
            functional.reset_net(self.model)
            with torch.amp.autocast(device_type=self.device if self.device != 'mps' else 'cpu', enabled=self.use_amp):
                with torch.set_grad_enabled(is_train):
                    logits, _, _ = self.model(input_ids, return_spikes=True, return_full_mems=True)
                    ensemble_logits.append(logits)
        
        ensemble_logits_tensor = torch.stack(ensemble_logits)
        
        # æå¤±è¨ˆç®— (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å…¨ä½“ã§)
        loss_dict = self.criterion(ensemble_logits_tensor, target_ids, torch.tensor(0.0), torch.tensor(0.0), self.model)

        if is_train:
            self.optimizer.zero_grad()
            if self.use_amp:
                self.scaler.scale(loss_dict['total']).backward()
                if self.grad_clip_norm > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss_dict['total'].backward()
                if self.grad_clip_norm > 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip_norm)
                self.optimizer.step()

        with torch.no_grad():
            mean_logits = ensemble_logits_tensor.mean(dim=0)
            preds = torch.argmax(mean_logits, dim=-1)
            if hasattr(self.criterion, 'ce_loss_fn') and hasattr(self.criterion.ce_loss_fn, 'ignore_index'):
                ignore_idx = self.criterion.ce_loss_fn.ignore_index
                mask = target_ids != ignore_idx
                num_masked_elements = cast(torch.Tensor, mask).sum()
                accuracy = (preds[mask] == target_ids[mask]).float().sum() / num_masked_elements if num_masked_elements > 0 else torch.tensor(0.0)
                loss_dict['accuracy'] = accuracy

        return {k: v.item() if torch.is_tensor(v) else v for k, v in loss_dict.items()}

class PlannerTrainer:
    def __init__(self, model: nn.Module, optimizer: torch.optim.Optimizer, criterion: nn.Module, device: str):
        self.model = model.to(device)
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device

    def train_epoch(self, dataloader: DataLoader, epoch: int):
        self.model.train()
        progress_bar = tqdm(dataloader, desc=f"Planner Training Epoch {epoch}")
        
        for batch in progress_bar:
            input_ids, target_plan = [t.to(self.device) for t in batch]

            self.optimizer.zero_grad()
            
            skill_logits, _, _ = self.model(input_ids)
            
            assert isinstance(self.criterion, PlannerLoss)
            loss_dict = self.criterion(skill_logits, target_plan)
            loss = loss_dict['total']
            
            loss.backward()
            self.optimizer.step()
            
            progress_bar.set_postfix({"loss": loss.item()})
            
class BPTTTrainer:
    def __init__(self, model: nn.Module, config: DictConfig):
        self.model = model
        self.config = config
        self.optimizer = Adam(self.model.parameters(), lr=config.training.learning_rate)
        self.criterion = torch.nn.CrossEntropyLoss()
        self.model_type = self.config.model.get("type", "simple")

    def _calculate_loss(self, outputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        if self.model_type == "spiking_transformer":
            return self.criterion(outputs.reshape(-1, outputs.size(-1)), targets.reshape(-1))
        else: # simple SNN
            T, B, V = outputs.shape
            S = targets.shape[1]
            assert T == S, f"Time dimension mismatch: {T} != {S}"
            return self.criterion(outputs.permute(1, 0, 2).reshape(-1, V), targets.reshape(-1))

    def train_step(self, data: torch.Tensor, targets: torch.Tensor) -> float:
        self.optimizer.zero_grad()

        if self.model_type == "spiking_transformer":
             outputs, _, _ = self.model(data)
        else:
             outputs = self.model(data)

        loss = self._calculate_loss(outputs, targets)
        
        loss.backward()
        self.optimizer.step()
        
        return loss.item()

class ParticleFilterTrainer:
    """
    é€æ¬¡ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æ³•ï¼ˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ï¼‰ã‚’ç”¨ã„ã¦ã€å¾®åˆ†ä¸å¯èƒ½ãªSNNã‚’å­¦ç¿’ã™ã‚‹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã€‚
    CPUä¸Šã§ã®å®Ÿè¡Œã‚’æƒ³å®šã—ã€GPUä¾å­˜ã‹ã‚‰è„±å´ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚
    """
    def __init__(self, base_model: BioSNN, config: Dict[str, Any], device: str):
        self.base_model = base_model.to(device)
        self.device = device
        self.config = config
        self.num_particles = config['training']['biologically_plausible']['particle_filter']['num_particles']
        self.noise_std = config['training']['biologically_plausible']['particle_filter']['noise_std']
        
        # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ï¼‰ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨ã—ã¦ä¿æŒ
        self.particles = [copy.deepcopy(self.base_model) for _ in range(self.num_particles)]
        self.particle_weights = torch.ones(self.num_particles, device=self.device) / self.num_particles
        print(f"ğŸŒªï¸ ParticleFilterTrainer initialized with {self.num_particles} particles.")

    def train_step(self, data: torch.Tensor, targets: torch.Tensor) -> float:
        """1ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’ï¼ˆäºˆæ¸¬ã€å°¤åº¦è¨ˆç®—ã€å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
        
        # 1. äºˆæ¸¬ & ãƒã‚¤ã‚ºä»˜åŠ  (å„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«)
        for particle in self.particles:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å°‘é‡ã®ãƒã‚¤ã‚ºã‚’åŠ ãˆã¦å¤šæ§˜æ€§ã‚’ç¶­æŒ
            with torch.no_grad():
                for param in particle.parameters():
                    param.add_(torch.randn_like(param) * self.noise_std)
        
        # 2. å°¤åº¦è¨ˆç®—
        # å„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ã©ã‚Œã ã‘ã†ã¾ãäºˆæ¸¬ã§ããŸã‹ã‚’è©•ä¾¡
        log_likelihoods = []
        for particle in self.particles:
            particle.eval()
            with torch.no_grad():
                if data.dim() > 1:
                    squeezed_data = data.squeeze(0)
                else:
                    squeezed_data = data

                input_spikes = (torch.rand_like(squeezed_data) > 0.5).float()
                outputs, _ = particle(input_spikes)
                
                if targets.dim() > 1:
                    squeezed_targets = targets.squeeze(0)
                else:
                    squeezed_targets = targets
                
                loss = F.mse_loss(outputs, squeezed_targets)
                log_likelihoods.append(-loss)
        
        # 3. é‡ã¿ã®æ›´æ–°ã¨æ­£è¦åŒ–
        log_likelihoods_tensor = torch.tensor(log_likelihoods, device=self.device)
        self.particle_weights *= torch.exp(log_likelihoods_tensor - log_likelihoods_tensor.max())
        
        if self.particle_weights.sum() > 0:
            self.particle_weights /= self.particle_weights.sum()
        else:
            self.particle_weights.fill_(1.0 / self.num_particles)

        # 4. å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (Resampling)
        if 1. / (self.particle_weights**2).sum() < self.num_particles / 2:
            indices = torch.multinomial(self.particle_weights, self.num_particles, replacement=True)
            new_particles = [copy.deepcopy(self.particles[i]) for i in indices]
            self.particles = new_particles
            self.particle_weights.fill_(1.0 / self.num_particles)
        
        best_particle_loss = -log_likelihoods_tensor.max().item()
        return best_particle_loss
