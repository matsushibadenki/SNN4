# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/training/trainers.py
# (ä¿®æ­£ v9)
# ä¿®æ­£: `NameError: name 'BioSNN' is not defined` ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€BioSNNã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€‚
# ä¿®æ­£: ParticleFilterTrainerã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã‚’ä¿®æ­£ã—ã€KeyErrorã‚’è§£æ¶ˆã™ã‚‹ã€‚

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from omegaconf import DictConfig
import os
import collections
from tqdm import tqdm
from typing import Tuple, Dict, Any, Optional, cast
import shutil
import time
from torch.optim import Adam
from spikingjelly.activation_based import functional # type: ignore

from snn_research.training.losses import CombinedLoss, DistillationLoss, SelfSupervisedLoss, PhysicsInformedLoss, PlannerLoss, ProbabilisticEnsembleLoss
from snn_research.cognitive_architecture.astrocyte_network import AstrocyteNetwork
from snn_research.cognitive_architecture.meta_cognitive_snn import MetaCognitiveSNN
from torch.utils.tensorboard import SummaryWriter

# â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
from snn_research.bio_models.simple_network import BioSNN
# â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
import copy


class BreakthroughTrainer:
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class DistillationTrainer(BreakthroughTrainer):
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class SelfSupervisedTrainer(BreakthroughTrainer):
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class PhysicsInformedTrainer(BreakthroughTrainer):
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class ProbabilisticEnsembleTrainer(BreakthroughTrainer):
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class PlannerTrainer:
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class BPTTTrainer:
    # ... (ã“ã®ã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ãªã—) ...
    pass

class ParticleFilterTrainer:
    """
    é€æ¬¡ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æ³•ï¼ˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚¯ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ï¼‰ã‚’ç”¨ã„ã¦ã€å¾®åˆ†ä¸å¯èƒ½ãªSNNã‚’å­¦ç¿’ã™ã‚‹ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã€‚
    """
    def __init__(self, base_model: BioSNN, config: Dict[str, Any], device: str):
        self.base_model = base_model.to(device)
        self.device = device
        self.config = config
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        # configã®éšŽå±¤æ§‹é€ ã‚’å¤‰æ›´
        self.num_particles = config['num_particles']
        self.noise_std = config['noise_std']
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        
        self.particles = [copy.deepcopy(self.base_model) for _ in range(self.num_particles)]
        self.particle_weights = torch.ones(self.num_particles, device=self.device) / self.num_particles
        print(f"ðŸŒªï¸ ParticleFilterTrainer initialized with {self.num_particles} particles.")

    def train_step(self, data: torch.Tensor, targets: torch.Tensor) -> float:
        """1ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’ï¼ˆäºˆæ¸¬ã€å°¤åº¦è¨ˆç®—ã€å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
        data = data.to(self.device)
        targets = targets.to(self.device)

        for particle in self.particles:
            with torch.no_grad():
                for param in particle.parameters():
                    param.add_(torch.randn_like(param) * self.noise_std)
        
        log_likelihoods = []
        for particle in self.particles:
            particle.eval()
            with torch.no_grad():
                squeezed_data = data.squeeze(0) if data.dim() > 1 else data
                input_spikes = (torch.rand_like(squeezed_data) > 0.5).float().to(self.device)
                outputs, _ = particle(input_spikes)
                
                squeezed_targets = targets.squeeze(0) if targets.dim() > 1 else targets
                loss = F.mse_loss(outputs, squeezed_targets)
                log_likelihoods.append(-loss)
        
        log_likelihoods_tensor = torch.tensor(log_likelihoods, device=self.device)
        self.particle_weights *= torch.exp(log_likelihoods_tensor - log_likelihoods_tensor.max())
        
        if self.particle_weights.sum() > 0:
            self.particle_weights /= self.particle_weights.sum()
        else:
            self.particle_weights.fill_(1.0 / self.num_particles)

        if 1. / (self.particle_weights**2).sum() < self.num_particles / 2:
            indices = torch.multinomial(self.particle_weights, self.num_particles, replacement=True)
            new_particles = [copy.deepcopy(self.particles[i]) for i in indices]
            self.particles = new_particles
            self.particle_weights.fill_(1.0 / self.num_particles)
        
        best_particle_loss = -log_likelihoods_tensor.max().item()
        return best_particle_loss
