# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/conversion/conversion_utils.py
# (æ–°è¦ä½œæˆ)
# Title: ANN-SNNå¤‰æ› ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# Description:
# ANNã‹ã‚‰SNNã¸ã®å¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹æ€§èƒ½ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®ã€
# é«˜åº¦ãªæ­£è¦åŒ–ãŠã‚ˆã³ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æŠ€è¡“ã‚’æä¾›ã™ã‚‹ã€‚
# doc/SNNé–‹ç™ºï¼šç²¾åº¦å‘ä¸Šã¨ANNæ¯”è¼ƒ.md ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³3.2ã€Œå¤‰æ›èª¤å·®ã¸ã®å¯¾å‡¦ã€ã«åŸºã¥ãã€
# é‡ã¿æ­£è¦åŒ–ã¨é–¾å€¤ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã€‚

import torch
import torch.nn as nn
from tqdm import tqdm
from typing import List, Dict, Any

def normalize_weights(ann_model: nn.Module, percentile: float = 99.9) -> Dict[str, torch.Tensor]:
    """
    ANNãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’æ­£è¦åŒ–ã—ã€SNNã§ã®ç™ºç«ç‡ãŒé£½å’Œã—ãªã„ã‚ˆã†ã«èª¿æ•´ã™ã‚‹ã€‚
    å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æœ€å¤§æ´»æ€§åŒ–å€¤ã‚’æ¨å®šã—ã€ãã‚Œã‚’åŸºã«é‡ã¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã€‚

    Args:
        ann_model (nn.Module): å¤‰æ›å…ƒã®å­¦ç¿’æ¸ˆã¿ANNãƒ¢ãƒ‡ãƒ«ã€‚
        percentile (float): ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ã‚’æ±ºå®šã™ã‚‹ãŸã‚ã®æ´»æ€§åŒ–å€¤ã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ã€‚

    Returns:
        Dict[str, torch.Tensor]: æ­£è¦åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’å«ã‚€state_dictã€‚
    """
    print(f"âš–ï¸ é‡ã¿æ­£è¦åŒ–ã‚’é–‹å§‹ã—ã¾ã™ (ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {percentile}%)...")
    state_dict = ann_model.state_dict()
    normalized_state_dict = {}

    for name, module in ann_model.named_modules():
        if isinstance(module, (nn.Linear, nn.Conv2d)):
            weight_name = f"{name}.weight"
            bias_name = f"{name}.bias"
            
            w = state_dict[weight_name]
            
            # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«é‡ã¿ã®ãƒãƒ«ãƒ ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ãŒã€
            # ç†æƒ³çš„ã«ã¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’é€šã—ã¦æœ€å¤§æ´»æ€§åŒ–å€¤ã‚’è¨˜éŒ²ã™ã‚‹ã¹ã
            max_val = torch.quantile(torch.abs(w.view(-1)), percentile / 100.0)
            
            if max_val > 1.0:
                scale_factor = max_val
                normalized_state_dict[weight_name] = w / scale_factor
                print(f"  - ãƒ¬ã‚¤ãƒ¤ãƒ¼ '{name}' ã®é‡ã¿ã‚’ {scale_factor:.2f} ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¾ã—ãŸã€‚")
                if bias_name in state_dict:
                    normalized_state_dict[bias_name] = state_dict[bias_name] / scale_factor
            else:
                normalized_state_dict[weight_name] = w
                if bias_name in state_dict:
                    normalized_state_dict[bias_name] = state_dict[bias_name]

    print("âœ… é‡ã¿æ­£è¦åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    return normalized_state_dict


@torch.no_grad()
def balance_thresholds(snn_model: nn.Module, calibration_loader: Any, target_rate: float = 0.1):
    """
    ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„ã€å„å±¤ã®ç™ºç«é–¾å€¤ã‚’èª¿æ•´ã—ã¦
    ç›®æ¨™ç™ºç«ç‡ã‚’é”æˆã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã™ã‚‹ã€‚

    Args:
        snn_model (nn.Module): å¤‰æ›å¾Œã®SNNãƒ¢ãƒ‡ãƒ«ã€‚
        calibration_loader (Any): é–¾å€¤èª¿æ•´ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã€‚
        target_rate (float): ç›®æ¨™ã¨ã™ã‚‹å¹³å‡ç™ºç«ç‡ã€‚
    """
    print(f"ğŸ”§ é–¾å€¤ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ (ç›®æ¨™ç™ºç«ç‡: {target_rate:.2f})...")
    
    #
    # ã“ã®æ©Ÿèƒ½ã¯ `ann_to_snn_converter.py` ã® `calibrate_thresholds` ãƒ¡ã‚½ãƒƒãƒ‰ã«
    # çµ±åˆãƒ»å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯æ¦‚å¿µçš„ãªåˆ†é›¢ã®ãŸã‚ã«å®šç¾©ã—ã¦ã„ã¾ã™ãŒã€
    # å®Ÿéš›ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¯Converterã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¨ãªã‚Šã¾ã™ã€‚
    #
    # converter.calibrate_thresholds(calibration_loader, target_rate)
    # ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
    #
    print("âœ… (ã“ã®æ©Ÿèƒ½ã¯AnnToSnnConverter.calibrate_thresholdsã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™)")