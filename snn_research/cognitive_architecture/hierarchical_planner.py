# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/hierarchical_planner.py
# (ä¿®æ­£)
# ä¿®æ­£ç‚¹: PlannerSNNã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ããªã‚Šã™ãã‚‹å•é¡Œã‚’ä¿®æ­£ã€‚
#         - RAGã§å–å¾—ã—ãŸçŸ¥è­˜ã‚’è¦ç´„ãƒ»åˆ‡ã‚Šè©°ã‚ã‚‹å‡¦ç†ã‚’è¿½åŠ ã€‚
#         - ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶å‘¼ã³å‡ºã—æ™‚ã«truncation=Trueã‚’æŒ‡å®šã—ã€å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§é•·ã«åˆ¶é™ã€‚

from typing import List, Dict, Any, Optional
import torch
from transformers import AutoTokenizer
import asyncio

from .planner_snn import PlannerSNN
from snn_research.distillation.model_registry import ModelRegistry
from .rag_snn import RAGSystem

class Plan:
    """
    ã‚¿ã‚¹ã‚¯ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’è¡¨ç¾ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self, goal: str, task_list: List[Dict[str, Any]]):
        self.goal = goal
        self.task_list = task_list

    def __repr__(self) -> str:
        return f"Plan(goal='{self.goal}', tasks={len(self.task_list)})"


class HierarchicalPlanner:
    """
    é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã™ã‚‹éšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€‚
    PlannerSNNã¨RAGSystemã‚’å†…éƒ¨ã§åˆ©ç”¨ã—ã¦ã€å‹•çš„ã«è¨ˆç”»ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    def __init__(
        self,
        model_registry: ModelRegistry,
        rag_system: RAGSystem,
        planner_model: Optional[PlannerSNN] = None,
        tokenizer_name: str = "gpt2",
        device: str = "cpu"
    ):
        self.model_registry = model_registry
        self.rag_system = rag_system
        self.planner_model = planner_model
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        if hasattr(self.tokenizer, 'model_max_length'):
            self.max_length = self.tokenizer.model_max_length
        else:
            self.max_length = 1024
        
        self.device = device
        if self.planner_model:
            self.planner_model.to(self.device)

        self.SKILL_MAP: Dict[int, Dict[str, Any]] = asyncio.run(self._build_skill_map())
        print(f"ğŸ§  Planner initialized with {len(self.SKILL_MAP)} skills from the registry.")

    async def _build_skill_map(self) -> Dict[int, Dict[str, Any]]:
        """ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰å‹•çš„ã«ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã‚’æ§‹ç¯‰ã™ã‚‹"""
        all_models = await self.model_registry.list_models()
        skill_map: Dict[int, Dict[str, Any]] = {}
        fallback_skill: Dict[str, Any] = {
            "task": "general_qa", 
            "description": "Answer a general question.", 
            "expert_id": "general_snn_v3"
        }
        
        for i, model_info in enumerate(all_models):
            skill_map[i] = {
                "task": model_info.get("model_id"),
                "description": model_info.get("task_description"),
                "expert_id": model_info.get("model_id")
            }
        
        if not any(skill['task'] == 'general_qa' for skill in skill_map.values()):
            skill_map[len(skill_map)] = fallback_skill
            
        return skill_map

    async def create_plan(self, high_level_goal: str, context: Optional[str] = None) -> Plan:
        """
        ç›®æ¨™ã«åŸºã¥ã„ã¦è¨ˆç”»ã‚’ä½œæˆã™ã‚‹ã€‚PlannerSNNãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã™ã‚‹ã€‚
        RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’æ´»ç”¨ã—ã¦ã€è¨˜å·æ¨è«–ã«åŸºã¥ã„ãŸè¨ˆç”»ã‚’è©¦ã¿ã‚‹ã€‚
        """
        print(f"ğŸŒ Creating plan for goal: {high_level_goal}")

        self.SKILL_MAP = await self._build_skill_map()

        if self.planner_model and len(self.SKILL_MAP) > 0:
            knowledge_query = f"Find concepts and relations for: {high_level_goal}"
            retrieved_knowledge = self.rag_system.search(knowledge_query, k=3)
            
            # å–å¾—ã—ãŸçŸ¥è­˜ãŒé•·ããªã‚Šã™ããªã„ã‚ˆã†ã«è¦ç´„ãƒ»åˆ‡ã‚Šè©°ã‚
            knowledge_summary = " ".join(doc[:250] + "..." for doc in retrieved_knowledge)
            if len(knowledge_summary) > 800:
                knowledge_summary = knowledge_summary[:800] + "..."

            full_prompt = f"Goal: {high_level_goal}\n\nRetrieved Knowledge:\n{knowledge_summary}"
            if context:
                full_prompt += f"\n\nUser Provided Context:\n{context}"
            
            print(f"ğŸ§  PlannerSNN is reasoning with prompt: {full_prompt[:250]}...")
            
            self.planner_model.eval()
            with torch.no_grad():
                # truncation=True ã‚’æŒ‡å®šã—ã¦ã€å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã®æœ€å¤§é•·ã«åˆ¶é™ã™ã‚‹
                inputs = self.tokenizer(
                    full_prompt, 
                    return_tensors="pt",
                    truncation=True,
                    max_length=self.max_length
                )
                input_ids = inputs['input_ids'].to(self.device)
                skill_logits, _, _ = self.planner_model(input_ids)
                predicted_skill_id = int(torch.argmax(skill_logits, dim=-1).item())
                
                if predicted_skill_id in self.SKILL_MAP:
                    task = self.SKILL_MAP[predicted_skill_id]
                    task_list = [task]
                    print(f"ğŸ§  PlannerSNN predicted skill ID: {predicted_skill_id} -> Task: {task.get('task')}")
                else:
                    print(f"âš ï¸ PlannerSNN predicted an invalid skill ID: {predicted_skill_id}. Falling back to causal planning.")
                    task_list = self._create_causal_plan(high_level_goal)
        else:
            print("âš ï¸ PlannerSNN not available. Attempting causal planning...")
            task_list = self._create_causal_plan(high_level_goal)

        if not task_list:
            print("âš ï¸ Causal planning failed. Falling back to rule-based planning.")
            task_list = self._create_rule_based_plan(high_level_goal)

        print(f"âœ… Plan created with {len(task_list)} step(s).")
        return Plan(goal=high_level_goal, task_list=task_list)

    def _create_causal_plan(self, high_level_goal: str) -> List[Dict[str, Any]]:
        """
        ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ï¼ˆRAGSystemï¼‰ã‚’æ¤œç´¢ã—ã€å› æœé–¢ä¿‚ã‚’è¾¿ã£ã¦è¨ˆç”»ã‚’æ¨è«–ã™ã‚‹ã€‚
        """
        print(f"ğŸ” Inferring plan from knowledge graph for: {high_level_goal}")
        task_list = []
        
        query = f"Goal: {high_level_goal}. Find skills or actions that achieve this."
        retrieved_docs = self.rag_system.search(query, k=3)
        
        available_skills = list(self.SKILL_MAP.values())

        for doc in retrieved_docs:
            for skill in available_skills:
                skill_name = (skill.get('task') or '').lower()
                if skill_name and skill_name in doc.lower():
                    if skill not in task_list:
                        print(f"  - Found relevant skill from KG: {skill_name}")
                        task_list.append(skill)
                        return task_list
        
        print("  - No direct causal path found in the knowledge graph.")
        return []

    def _create_rule_based_plan(self, prompt: str) -> List[Dict[str, Any]]:
        """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç°¡æ˜“çš„ãªè¨ˆç”»ã‚’ä½œæˆã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰ã€‚"""
        task_list = []
        prompt_lower = prompt.lower()
        
        available_skills = list(self.SKILL_MAP.values())
        
        for skill in available_skills:
            task_keywords = (skill.get('task') or '').lower().split('_')
            desc_keywords = (skill.get('description') or '').lower().split()
            
            if any(kw in prompt_lower for kw in task_keywords if kw) or any(kw in prompt_lower for kw in desc_keywords if kw):
                 if skill not in task_list:
                    task_list.append(skill)

        if not task_list:
            fallback_skill = next((s for s in available_skills if "general" in (s.get("task") or "")), None)
            if fallback_skill:
                task_list.append(fallback_skill)
        
        return task_list

    async def refine_plan(self, failed_task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å¤±æ•—ã—ãŸã‚¿ã‚¹ã‚¯ã®ä»£æ›¿æ¡ˆï¼ˆå”åŠ›è€…ï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚
        """
        task_desc = failed_task.get("description", "")
        print(f"ğŸ¤” Refining plan for failed task: {task_desc}")

        alternative_experts = await self.model_registry.find_models_for_task(str(task_desc), top_k=5)

        original_expert_id = failed_task.get("expert_id")
        for expert in alternative_experts:
            if expert.get("model_id") != original_expert_id:
                print(f"âœ… Found alternative expert: {expert['model_id']}")
                new_task: Dict[str, Any] = failed_task.copy()
                new_task["expert_id"] = expert["model_id"]
                new_task["description"] = expert["task_description"]
                return new_task
        
        print("âŒ No alternative expert found.")
        return None

    def execute_task(self, task_request: str, context: str) -> Optional[str]:
        """
        ã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’å—ã‘å–ã‚Šã€è¨ˆç”»ç«‹æ¡ˆã‹ã‚‰å®Ÿè¡Œã¾ã§ã‚’è¡Œã†ã€‚
        """
        print(f"Executing task: {task_request} with context: {context}")
        
        plan = asyncio.run(self.create_plan(task_request, context))
        
        if plan.task_list:
            final_result = f"Plan for '{task_request}':\n"
            for i, task in enumerate(plan.task_list):
                final_result += f"  Step {i+1}: Execute '{task.get('task')}' using expert '{task.get('expert_id')}'.\n"
            final_result += "Task completed successfully (dummy execution)."
            return final_result
        else:
            return "Could not create a plan for the given task."