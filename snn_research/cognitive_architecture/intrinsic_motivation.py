# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/cognitive_architecture/intrinsic_motivation.py
# æ”¹å–„ç‚¹:
# - å¥½å¥‡å¿ƒã®æºæ³‰ã¨ãªã£ãŸæ–‡è„ˆï¼ˆäºˆæ¸¬èª¤å·®ãŒæœ€å¤§ã ã£ãŸæ™‚ã®æƒ…å ±ï¼‰ã‚’è¨˜éŒ²ã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚

import numpy as np
from collections import deque
from typing import Dict, Any, Optional

class IntrinsicMotivationSystem:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å†…éƒ¨çŠ¶æ…‹ï¼ˆå¥½å¥‡å¿ƒã€è‡ªä¿¡ã€é€€å±ˆï¼‰ã¨ã€ãã®æºæ³‰ã‚’ç®¡ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚
    """
    def __init__(self, history_length: int = 100):
        self.prediction_errors = deque(maxlen=history_length)
        self.task_success_rates = deque(maxlen=history_length)
        self.task_similarities = deque(maxlen=history_length)
        self.loss_history = deque(maxlen=history_length)
        # --- â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ã“ã“ã‹ã‚‰ãŒé‡è¦â†“â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸ ---
        # å¥½å¥‡å¿ƒã®å¯¾è±¡ã‚’è¨˜éŒ²ã™ã‚‹
        self.curiosity_context: Optional[Any] = None
        self.max_prediction_error: float = 0.0
        # --- â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ã“ã“ã¾ã§ãŒé‡è¦â†‘â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸ ---

    def update_metrics(self, prediction_error: float, success_rate: float, task_similarity: float, loss: float, context: Optional[Any] = None):
        """
        æœ€æ–°ã®ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœã‹ã‚‰å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°ã™ã‚‹ã€‚
        """
        self.prediction_errors.append(prediction_error)
        self.task_success_rates.append(success_rate)
        self.task_similarities.append(task_similarity)
        self.loss_history.append(loss)

        # --- â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ã“ã“ã‹ã‚‰ãŒé‡è¦â†“â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸ ---
        # éå»æœ€å¤§ã®äºˆæ¸¬èª¤å·®ã§ã‚ã‚Œã°ã€ãã®æ™‚ã®æ–‡è„ˆã‚’ã€Œæœ€ã‚‚èˆˆå‘³æ·±ã„ã“ã¨ã€ã¨ã—ã¦è¨˜æ†¶
        if prediction_error > self.max_prediction_error:
            self.max_prediction_error = prediction_error
            self.curiosity_context = context
            print(f"ğŸŒŸ æ–°ã—ã„å¥½å¥‡å¿ƒã®å¯¾è±¡ã‚’ç™ºè¦‹: {str(context)[:100]}")
        # --- â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ã“ã“ã¾ã§ãŒé‡è¦â†‘â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸ ---

    def get_internal_state(self) -> Dict[str, Any]:
        """
        ç¾åœ¨ã®å†…éƒ¨çŠ¶æ…‹ã‚’å®šé‡çš„ãªæŒ‡æ¨™ã¨ã—ã¦è¨ˆç®—ã™ã‚‹ã€‚
        """
        state = {
            "curiosity": self._calculate_curiosity(),
            "confidence": self._calculate_confidence(),
            "boredom": self._calculate_boredom(),
            # --- â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ã“ã“ã‹ã‚‰ãŒé‡è¦â†“â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸ ---
            "curiosity_context": self.curiosity_context
            # --- â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ã“ã“ã¾ã§ãŒé‡è¦â†‘â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸ ---
        }
        return state

    def _calculate_curiosity(self) -> float:
        # (å¤‰æ›´ãªã—)
        if not self.prediction_errors:
            return 0.5
        return np.mean(self.prediction_errors)

    def _calculate_confidence(self) -> float:
        # (å¤‰æ›´ãªã—)
        if not self.task_success_rates:
            return 0.5
        return np.mean(self.task_success_rates)

    def _calculate_boredom(self) -> float:
        # (å¤‰æ›´ãªã—)
        if len(self.loss_history) < 2: return 0.0
        loss_change_rate = np.mean(np.abs(np.diff(list(self.loss_history))))
        stagnation = 1.0 - np.tanh(loss_change_rate * 10)
        avg_similarity = np.mean(self.task_similarities)
        return stagnation * avg_similarity
