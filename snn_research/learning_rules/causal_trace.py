# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: snn_research/learning_rules/causal_trace.py
# (ä¿®æ­£)
# ä¿®æ­£: è¦ªã‚¯ãƒ©ã‚¹ã®updateãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ã‚ˆã†ã«ãªã£ãŸãŸã‚ã€ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯ã—ã¦ä½¿ç”¨ã™ã‚‹ã€‚
# æ”¹å–„:
# - å› æžœçš„è²¢çŒ®åº¦ã‚’è¿½è·¡ã™ã‚‹`causal_contribution`ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’è¿½åŠ ã€‚
# - æˆ»ã‚Šå€¤ã¨ã—ã¦ã€å‰æ®µã®å±¤ã«ä¼ãˆã‚‹ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·`backward_credit`ã‚’æ˜Žç¢ºã«è¨ˆç®—ã—ã¦è¿”ã™ã€‚

import torch
from typing import Dict, Any, Optional, Tuple
from .reward_modulated_stdp import RewardModulatedSTDP

class CausalTraceCreditAssignment(RewardModulatedSTDP):
    """
    å ±é…¬ä¿¡å·ã¨éšŽå±¤çš„ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·ã«åŸºã¥ãé‡ã¿ã‚’æ›´æ–°ã—ã€
    å‰æ®µã¸ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·ã‚’ç”Ÿæˆã™ã‚‹ã€é€²åŒ–ã—ãŸå› æžœå­¦ç¿’å‰‡ã€‚
    """
    def __init__(self, learning_rate: float, a_plus: float, a_minus: float, tau_trace: float, tau_eligibility: float, dt: float = 1.0):
        super().__init__(learning_rate, a_plus, a_minus, tau_trace, tau_eligibility, dt)
        # é•·æœŸçš„ãªå› æžœçš„è²¢çŒ®åº¦ã‚’è¨˜éŒ²ã™ã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹
        self.causal_contribution: Optional[torch.Tensor] = None
        print("ðŸ§  Advanced Causal Trace Credit Assignment rule initialized.")

    def _initialize_contribution_trace(self, weight_shape: tuple, device: torch.device):
        """å› æžœçš„è²¢çŒ®åº¦ã‚’è¨˜éŒ²ã™ã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚"""
        self.causal_contribution = torch.zeros(weight_shape, device=device)

    def update(
        self,
        pre_spikes: torch.Tensor,
        post_spikes: torch.Tensor,
        weights: torch.Tensor,
        optional_params: Optional[Dict[str, Any]] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å ±é…¬ä¿¡å·ã¨å¾Œæ®µã‹ã‚‰ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã«åŸºã¥ãé‡ã¿å¤‰åŒ–é‡ã‚’è¨ˆç®—ã—ã€
        å‰æ®µã¸ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·ã‚’ç”Ÿæˆã—ã¦è¿”ã™ã€‚
        """
        # è¦ªã‚¯ãƒ©ã‚¹(RewardModulatedSTDP)ã®updateã‚’å‘¼ã³å‡ºã—ã€åŸºæœ¬çš„ãªé‡ã¿å¤‰åŒ–é‡dwã‚’è¨ˆç®—
        dw, _ = super().update(pre_spikes, post_spikes, weights, optional_params)

        # å› æžœçš„è²¢çŒ®åº¦ãƒˆãƒ¬ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        if self.causal_contribution is None or self.causal_contribution.shape != weights.shape:
            self._initialize_contribution_trace(weights.shape, weights.device)
        
        assert self.causal_contribution is not None, "Causal contribution trace not initialized."

        # å ±é…¬ãŒç™ºç”Ÿã—ãŸå ´åˆã€ãã®é‡ã¿å¤‰åŒ–ã®å¤§ãã•ã‚’é•·æœŸçš„ãªè²¢çŒ®åº¦ã¨ã—ã¦è¨˜éŒ²ï¼ˆæŒ‡æ•°ç§»å‹•å¹³å‡ï¼‰
        if optional_params and optional_params.get("reward", 0.0) != 0.0:
            self.causal_contribution = self.causal_contribution * 0.99 + torch.abs(dw) * 0.01

        # ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·ã®é€†æ–¹å‘ä¼æ’­
        # é©æ ¼åº¦ãƒˆãƒ¬ãƒ¼ã‚¹(eligibility_trace)ã¨ç¾åœ¨ã®é‡ã¿ã«åŸºã¥ã„ã¦ã€
        # ã“ã®å±¤ã®ç™ºç«(post_spikes)ã«è²¢çŒ®ã—ãŸå‰æ®µã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³(pre_spikes)ã¸ã®
        # ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’è¨ˆç®—ã™ã‚‹ã€‚
        if self.eligibility_trace is not None:
            # backward_creditã®å½¢çŠ¶ã¯ pre_spikes ã¨åŒã˜ã«ãªã‚‹
            backward_credit = torch.einsum('ij,j->i', weights, self.eligibility_trace.sum(dim=0))
        else:
            backward_credit = torch.zeros_like(pre_spikes)

        return dw, backward_credit