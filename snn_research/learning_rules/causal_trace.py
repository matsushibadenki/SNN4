# snn_research/learning_rules/causal_trace.py
# (ä¿®æ­£)
# ä¿®æ­£: è¦ªã‚¯ãƒ©ã‚¹ã®updateãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ã‚ˆã†ã«ãªã£ãŸãŸã‚ã€ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯ã—ã¦ä½¿ç”¨ã™ã‚‹ã€‚

import torch
from typing import Dict, Any, Optional, Tuple
from .reward_modulated_stdp import RewardModulatedSTDP

class CausalTraceCreditAssignment(RewardModulatedSTDP):
    # ... (init, _initialize_contribution_trace ã¯å¤‰æ›´ãªã—) ...
    def __init__(self, learning_rate: float, a_plus: float, a_minus: float, tau_trace: float, tau_eligibility: float, dt: float = 1.0):
        super().__init__(learning_rate, a_plus, a_minus, tau_trace, tau_eligibility, dt)
        self.causal_contribution: Optional[torch.Tensor] = None
        print("ðŸ§  Causal Trace Credit Assignment learning rule initialized.")

    def _initialize_contribution_trace(self, weight_shape: tuple, device: torch.device):
        """å› æžœçš„è²¢çŒ®åº¦ã‚’è¨˜éŒ²ã™ã‚‹ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹ã€‚"""
        self.causal_contribution = torch.zeros(weight_shape, device=device)

    def update(
        self,
        pre_spikes: torch.Tensor,
        post_spikes: torch.Tensor,
        weights: torch.Tensor,
        optional_params: Optional[Dict[str, Any]] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å ±é…¬ä¿¡å·ã¨å¾Œæ®µã‹ã‚‰ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã«åŸºã¥ãé‡ã¿å¤‰åŒ–é‡ã‚’è¨ˆç®—ã—ã€
        å‰æ®µã¸ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆä¿¡å·ã‚’ç”Ÿæˆã—ã¦è¿”ã™ã€‚
        """
        # è¦ªã‚¯ãƒ©ã‚¹ã®updateã¯ (dw, None) ã‚’è¿”ã™ã®ã§ã€å¿…è¦ãªdwã®ã¿å—ã‘å–ã‚‹
        dw, _ = super().update(pre_spikes, post_spikes, weights, optional_params)

        if self.causal_contribution is None or self.causal_contribution.shape != weights.shape:
            self._initialize_contribution_trace(weights.shape, weights.device)
        
        assert self.causal_contribution is not None, "Causal contribution trace not initialized."

        if optional_params and optional_params.get("reward", 0.0) != 0.0:
            self.causal_contribution = self.causal_contribution * 0.99 + torch.abs(dw) * 0.01

        if self.eligibility_trace is not None:
            backward_credit = torch.einsum('ij,ij->j', self.eligibility_trace, weights)
        else:
            backward_credit = torch.zeros_like(pre_spikes)

        return dw, backward_credit